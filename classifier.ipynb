{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import cv2, \n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import optimizers\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './cats_and_dogs_filtered/train/'\n",
    "TEST_DIR = './cats_and_dogs_filtered/validation/'\n",
    "\n",
    "ROWS = 150\n",
    "COLS = 150\n",
    "CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 100\n"
     ]
    }
   ],
   "source": [
    "# Criando uma lista das imagens de treino totais e listas separadas para cada animal\n",
    "original_train_images=[]\n",
    "for i in os.listdir(TRAIN_DIR):\n",
    "    #original_train_images.append(os.listdir(TRAIN_DIR+i))\n",
    "    if i == 'dogs':\n",
    "        train_dogs = os.listdir(TRAIN_DIR+i)\n",
    "    if i == 'cats':\n",
    "        train_cats = os.listdir(TRAIN_DIR+i)\n",
    "    for images in os.listdir(TRAIN_DIR+i):\n",
    "        original_train_images.append(f'{TRAIN_DIR}{i}/{images}')\n",
    "\n",
    "random.shuffle(original_train_images)\n",
    "\n",
    "#Separando a base de dados de treinamento em treinamento e validação\n",
    "train_images = original_train_images[:1900]\n",
    "validation_images = original_train_images[1900:]\n",
    "print(len(train_images),len(validation_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=[]\n",
    "for i in os.listdir(TEST_DIR):\n",
    "    #print(TEST_DIR+i)\n",
    "    for images in os.listdir(TEST_DIR+i):\n",
    "        test_images.append(f'{TEST_DIR}{i}/{images}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arr(arr):\n",
    "    plt.figure()\n",
    "    plt.imshow(image.array_to_img(arr))\n",
    "    plt.show()\n",
    "\n",
    "def plot(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    X = np.ndarray((count, ROWS, COLS, CHANNELS), dtype=np.float32)\n",
    "    y = np.zeros((count,), dtype=np.float32)\n",
    "    print(\"Starting\")\n",
    "    for i, image_file in enumerate(images):\n",
    "        img = image.load_img(image_file, target_size=(ROWS, COLS))\n",
    "        X[i] = image.img_to_array(img)\n",
    "        if 'dog.' in image_file:\n",
    "            y[i] = 1.\n",
    "        i+=1\n",
    "        if i == count:\n",
    "            print('Processed {} of {}'.format(i, count))\n",
    "        else:\n",
    "            if i%1000 == 0: print('Processed {} of {}'.format(i, count))\n",
    "        \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Processed 1000 of 1900\n",
      "Processed 1900 of 1900\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = prep_data(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Processed 100 of 100\n"
     ]
    }
   ],
   "source": [
    "X_validation, y_validation = prep_data(validation_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "validation_datagen = image.ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_generator = validation_datagen.flow(\n",
    "    X_validation,\n",
    "    y_validation,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(ROWS, COLS, CHANNELS)))\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# #     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# #     model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# #     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# #     model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "# #     model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     # model.add(Dropout(0.5))\n",
    "\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(512, activation='relu'))\n",
    "#     # model.add(Dense(1024, activation='relu'))\n",
    "#     # model.add(Dense(1000, activation='relu'))\n",
    "#     # model.add(Dropout(0.5))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     return model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(ROWS, COLS, CHANNELS)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                5308480   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,327,937\n",
      "Trainable params: 5,327,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=\"adam\",\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n"
     ]
    }
   ],
   "source": [
    "train_steps = len(train_images)/BATCH_SIZE\n",
    "validation_steps = len(validation_images)/BATCH_SIZE\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "#     steps_per_epoch=len(train_generator),\n",
    "    epochs=11,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "#     validation_steps=len(validation_generator),\n",
    "    verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dogs-v-cat-data-augmentation-04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
